{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from local_utils import init_embeddings\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Constants for file paths\n",
    "EMBEDDINGS_PATH = \"/home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/model_240000_DoppelVer_All_112x112_outputs.pth\"\n",
    "EMBEDDINGS_IMAGE_PATH = \"/home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/model_240000_DoppelVer_All_112x112_image_paths.txt\"\n",
    "IMAGE_DIR = \"/home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/DoppelVer_All_112x112\"\n",
    "BASE_PATH = \"/home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/results\"\n",
    "CLASS_NUM_NAME_PATH = \"/home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/class_num_name.csv\"\n",
    "\n",
    "embeddings = init_embeddings(EMBEDDINGS_PATH, EMBEDDINGS_IMAGE_PATH, IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering_per_person(embeddings, base_path, n_clusters=1):\n",
    "    # Ensure the base directory exists\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    \n",
    "    results = []\n",
    "    filename = os.path.join(base_path, \"KMeans_Clustering_Per_Person.csv\")\n",
    "\n",
    "    # Exclude the last 3 columns: 'class', 'path', and 'class_num'\n",
    "    embedding_columns = embeddings.columns[:-3]\n",
    "\n",
    "    for person_index in tqdm(embedding_columns, desc=\"Clustering Each Person\"):\n",
    "        # Extract and scale data for the current person (column)\n",
    "        person_data = embeddings[person_index].values.reshape(-1, 1)\n",
    "        person_data_scaled = StandardScaler().fit_transform(person_data)\n",
    "        \n",
    "        # Apply KMeans clustering\n",
    "        clusterer = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        labels = clusterer.fit_predict(person_data_scaled)\n",
    "        \n",
    "        # Collect results\n",
    "        for idx, label in enumerate(labels):\n",
    "            results.append({\n",
    "                'person_index': person_index,\n",
    "                'data_point_index': idx,\n",
    "                'label': label\n",
    "            })\n",
    "\n",
    "    # Save all results at once to minimize file I/O operations\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_midpoint_and_furthest_distance_per_person(embeddings, base_path, class_num_name_df):\n",
    "    # Ensure the base directory exists\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    \n",
    "    midpoints = []\n",
    "    filename = os.path.join(base_path, \"Midpoints_Per_Person_With_Class_Names.csv\")\n",
    "\n",
    "    for person_index in tqdm(embeddings.columns[:-3], desc=\"Calculating Midpoints for Each Person\"):\n",
    "        # Extract data for the current person (column)\n",
    "        person_data = embeddings[person_index].values\n",
    "        \n",
    "        # Calculate the midpoint (mean) of the cluster\n",
    "        midpoint = np.mean(person_data)\n",
    "        \n",
    "        # Calculate the distance from the midpoint to each point in the cluster\n",
    "        distances = np.abs(person_data - midpoint)\n",
    "        \n",
    "        # Find the maximum distance (furthest point)\n",
    "        max_distance = np.max(distances)\n",
    "        \n",
    "        # Get the corresponding class_num and class_name\n",
    "        class_num = embeddings.loc[:, person_index].name\n",
    "        class_name_row = class_num_name_df[class_num_name_df['class_num'] == class_num]\n",
    "\n",
    "        if class_name_row.empty:\n",
    "            #print(f\"Class number {class_num} not found in class_num_name_df\")\n",
    "            continue\n",
    "\n",
    "        class_name = class_name_row['class'].values[0]\n",
    "        \n",
    "        # Collect results\n",
    "        midpoints.append({\n",
    "            'person_index': person_index,\n",
    "            'class_num': class_num,\n",
    "            'class': class_name,\n",
    "            'midpoint': midpoint,\n",
    "            'max_distance': max_distance\n",
    "        })\n",
    "\n",
    "    # Convert midpoints to DataFrame\n",
    "    midpoints_df = pd.DataFrame(midpoints)\n",
    "    \n",
    "    # Save all results at once to minimize file I/O operations\n",
    "    midpoints_df.to_csv(filename, index=False)\n",
    "    \n",
    "    return midpoints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_difference(midpoints_df, output_path):\n",
    "    # Calculate the difference\n",
    "    midpoints_df['difference'] = midpoints_df['max_distance'] - midpoints_df['midpoint']\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = os.path.join(output_path, \"Midpoints_With_Difference.csv\")\n",
    "    midpoints_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyperspheres_and_calculate_overlap(embeddings, base_path, class_num_name_df):\n",
    "    # Ensure the base directory exists\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    \n",
    "    hyperspheres = []\n",
    "    overlap_results = []\n",
    "    filename = os.path.join(base_path, \"Hyperspheres_Per_Person.csv\")\n",
    "    overlap_filename = os.path.join(base_path, \"Hypersphere_Overlap_Per_Person.csv\")\n",
    "\n",
    "    for person_index in tqdm(embeddings.columns[:-3], desc=\"Calculating Hyperspheres for Each Person\"):\n",
    "        # Extract data for the current person (column)\n",
    "        person_data = embeddings[person_index].values\n",
    "        \n",
    "        # Calculate the midpoint (mean) of the cluster\n",
    "        midpoint = np.mean(person_data)\n",
    "        \n",
    "        # Calculate the distance from the midpoint to each point in the cluster\n",
    "        distances = np.abs(person_data - midpoint)\n",
    "        \n",
    "        # Find the maximum distance (furthest point)\n",
    "        max_distance = np.max(distances)\n",
    "        \n",
    "        # Get the corresponding class_num and class_name\n",
    "        class_num = embeddings.loc[:, person_index].name\n",
    "        class_name_row = class_num_name_df[class_num_name_df['class_num'] == class_num]\n",
    "\n",
    "        if class_name_row.empty:\n",
    "            continue\n",
    "\n",
    "        class_name = class_name_row['class'].values[0]\n",
    "        \n",
    "        # Collect results\n",
    "        hyperspheres.append({\n",
    "            'person_index': person_index,\n",
    "            'class_num': class_num,\n",
    "            'class': class_name,\n",
    "            'midpoint': midpoint,\n",
    "            'radius': max_distance  # Radius is the same as max_distance\n",
    "        })\n",
    "\n",
    "    # Calculate overlap with other hyperspheres\n",
    "    for i in range(len(hyperspheres)):\n",
    "        for j in range(i + 1, len(hyperspheres)):\n",
    "            hypersphere_1 = hyperspheres[i]\n",
    "            hypersphere_2 = hyperspheres[j]\n",
    "            \n",
    "            # Calculate distance between midpoints (since midpoints are scalars, just use abs difference)\n",
    "            distance_between_centers = abs(hypersphere_1['midpoint'] - hypersphere_2['midpoint'])\n",
    "            \n",
    "            # Check for overlap\n",
    "            if distance_between_centers < (hypersphere_1['radius'] + hypersphere_2['radius']):\n",
    "                overlap_percentage = (1 - distance_between_centers / (hypersphere_1['radius'] + hypersphere_2['radius'])) * 100\n",
    "                overlap_results.append({\n",
    "                    'person_index_1': hypersphere_1['person_index'],\n",
    "                    'class_1': hypersphere_1['class'],\n",
    "                    'person_index_2': hypersphere_2['person_index'],\n",
    "                    'class_2': hypersphere_2['class'],\n",
    "                    'overlap_percentage': overlap_percentage\n",
    "                })\n",
    "\n",
    "    # Convert hyperspheres to DataFrame\n",
    "    hyperspheres_df = pd.DataFrame(hyperspheres)\n",
    "    \n",
    "    # Save all results at once to minimize file I/O operations\n",
    "    hyperspheres_df.to_csv(filename, index=False)\n",
    "\n",
    "    # Convert overlap results to DataFrame\n",
    "    overlap_df = pd.DataFrame(overlap_results)\n",
    "    \n",
    "    # Save overlap results to CSV\n",
    "    overlap_df.to_csv(overlap_filename, index=False)\n",
    "    \n",
    "    return hyperspheres_df, overlap_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering Each Person: 100%|██████████| 512/512 [00:12<00:00, 39.62it/s]\n",
      "Calculating Midpoints for Each Person: 100%|██████████| 512/512 [00:00<00:00, 1359.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform Clustering\n",
    "perform_clustering_per_person(embeddings, BASE_PATH)\n",
    "\n",
    "# Find Midpoints for Each Person and Include Class Names\n",
    "class_num_name_df = pd.read_csv(CLASS_NUM_NAME_PATH)\n",
    "midpoints = find_midpoint_and_furthest_distance_per_person(embeddings, BASE_PATH, class_num_name_df)\n",
    "calculate_difference(midpoints, BASE_PATH)\n",
    "\n",
    "csv_path = os.path.join(BASE_PATH, \"Midpoints_Per_Person_With_Class_Names.csv\")\n",
    "midpoints_df = pd.read_csv(csv_path)\n",
    "#print(midpoints_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Hyperspheres for Each Person: 100%|██████████| 512/512 [00:00<00:00, 1366.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_num_name_df = pd.read_csv(CLASS_NUM_NAME_PATH)\n",
    "hyperspheres, overlaps = create_hyperspheres_and_calculate_overlap(embeddings, BASE_PATH, class_num_name_df)\n",
    "\n",
    "hypersphere_file = os.path.join(BASE_PATH, \"Hyperspheres_Per_Person.csv\")\n",
    "overlap_file = os.path.join(BASE_PATH, \"Hypersphere_Overlap_Per_Person.csv\")\n",
    "    \n",
    "hyperspheres_df = pd.read_csv(hypersphere_file)\n",
    "overlaps_df = pd.read_csv(overlap_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted CSV saved to /home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/results/Hypersphere_Overlap_ordered.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "input_csv_path = '/home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/results/Hypersphere_Overlap_Per_Person.csv'  \n",
    "output_csv_path = '/home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/results/Hypersphere_Overlap_ordered.csv' \n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Sort the DataFrame by the overlap_percentage column in ascending order\n",
    "sorted_df = df.sort_values(by='overlap_percentage')\n",
    "\n",
    "# Save the sorted DataFrame to a new CSV file\n",
    "sorted_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Sorted CSV saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "input_csv_path = '/home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/results/Hypersphere_Overlap_Per_Person.csv'  # Update with your sorted input CSV path\n",
    "output_graphs_path = '/home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/results/Graphs'  # Update with your desired output directory for graphs\n",
    "\n",
    "os.makedirs(output_graphs_path, exist_ok=True)\n",
    "\n",
    "# Read the sorted CSV file\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Get unique classes\n",
    "unique_classes = df['class_1'].unique()\n",
    "\n",
    "# Plot a graph for each class\n",
    "for class_name in unique_classes:\n",
    "    # Filter data for the current class\n",
    "    class_df = df[df['class_1'] == class_name]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(len(class_df)), class_df['overlap_percentage'], marker='o', linestyle='-', color='b', markersize=5)\n",
    "    \n",
    "    # Highlight points with significantly lower overlap\n",
    "    low_overlap_threshold = 80\n",
    "    low_overlap_points = class_df[class_df['overlap_percentage'] < low_overlap_threshold]\n",
    "    plt.scatter(low_overlap_points.index, low_overlap_points['overlap_percentage'], color='red', label='Low Overlap (< 80%)')\n",
    "\n",
    "    plt.title(f'Overlap Percentage Changes for {class_name}', fontsize=16)\n",
    "    plt.xlabel('Comparison Index', fontsize=14)\n",
    "    plt.ylabel('Overlap Percentage', fontsize=14)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot\n",
    "    graph_path = os.path.join(output_graphs_path, f'{class_name}_overlap_changes.png')\n",
    "    plt.savefig(graph_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High overlap comparisons (>= 99%):\n",
      "       person_index_1          class_1  person_index_2           class_2  \\\n",
      "2                   0  Abigail_Spencer               3       Alex_Newell   \n",
      "9                   0  Abigail_Spencer              10       Allen_Leech   \n",
      "21                  0  Abigail_Spencer              22  Annabelle_Wallis   \n",
      "47                  0  Abigail_Spencer              48     Bridget_Regan   \n",
      "57                  0  Abigail_Spencer              58    Cara_Delevigne   \n",
      "...               ...              ...             ...               ...   \n",
      "75829             382    William_Dafoe             385    Zachary_Quinto   \n",
      "75832             382    William_Dafoe             388   Zooey_Deschanel   \n",
      "75842             384       Zach_Braff             387       Zoey_Deutch   \n",
      "75845             385   Zachary_Quinto             386       Zoe_Saldana   \n",
      "75847             385   Zachary_Quinto             388   Zooey_Deschanel   \n",
      "\n",
      "       overlap_percentage  \n",
      "2               99.493117  \n",
      "9               99.387429  \n",
      "21              99.851199  \n",
      "47              99.156762  \n",
      "57              99.909776  \n",
      "...                   ...  \n",
      "75829           99.327856  \n",
      "75832           99.885710  \n",
      "75842           99.310805  \n",
      "75845           99.557311  \n",
      "75847           99.166640  \n",
      "\n",
      "[10980 rows x 5 columns]\n",
      "\n",
      "Low overlap comparisons (< 80%):\n",
      "       person_index_1             class_1  person_index_2             class_2  \\\n",
      "4693               12         Amber_Heard             104       Donald_Glover   \n",
      "8774               23       Anne_Hathaway             104       Donald_Glover   \n",
      "9139               24        Ansel_Elgort             104       Donald_Glover   \n",
      "11666              31  Augusta_Xu-Holland             104       Donald_Glover   \n",
      "12734              34        Barack_Obama             104       Donald_Glover   \n",
      "19624              54         Burn_Gorman             104       Donald_Glover   \n",
      "20291              56      Camila_Cabello             104       Donald_Glover   \n",
      "27983              80      Clint_Eastwood             104       Donald_Glover   \n",
      "29513              85      Dakota_Fanning             104       Donald_Glover   \n",
      "35114             104       Donald_Glover             119    Elizabeth_Reaser   \n",
      "35131             104       Donald_Glover             136        Gavin_Degraw   \n",
      "35138             104       Donald_Glover             143         Goldie_Hawn   \n",
      "35141             104       Donald_Glover             146           Greta_Lee   \n",
      "35151             104       Donald_Glover             156         Hilary_Duff   \n",
      "35163             104       Donald_Glover             168  Jada_Pinkett_Smith   \n",
      "35224             104       Donald_Glover             229         Kelly_Lynch   \n",
      "35240             104       Donald_Glover             245         Kurt_Russel   \n",
      "35261             104       Donald_Glover             266       Margot_Robbie   \n",
      "35284             104       Donald_Glover             289     Natasha_Leggero   \n",
      "35306             104       Donald_Glover             311       Paul_Wahlberg   \n",
      "35317             104       Donald_Glover             322       Pyper_America   \n",
      "48837             157        Hugh_Jackman             168  Jada_Pinkett_Smith   \n",
      "51325             168  Jada_Pinkett_Smith             170        Jai_Courtney   \n",
      "51383             168  Jada_Pinkett_Smith             228     Keira_Knightley   \n",
      "51442             168  Jada_Pinkett_Smith             287  Natalia_Lafourcade   \n",
      "51518             168  Jada_Pinkett_Smith             363      Taylor_Lautner   \n",
      "51544             168  Jada_Pinkett_Smith             389       Zooey_Kravitz   \n",
      "\n",
      "       overlap_percentage  \n",
      "4693            77.910553  \n",
      "8774            79.730509  \n",
      "9139            79.682973  \n",
      "11666           79.481012  \n",
      "12734           78.856020  \n",
      "19624           79.120407  \n",
      "20291           79.811871  \n",
      "27983           78.795968  \n",
      "29513           76.047531  \n",
      "35114           78.212912  \n",
      "35131           77.907296  \n",
      "35138           78.378348  \n",
      "35141           79.332714  \n",
      "35151           76.131365  \n",
      "35163           75.441849  \n",
      "35224           77.808103  \n",
      "35240           78.061651  \n",
      "35261           79.361306  \n",
      "35284           79.946245  \n",
      "35306           77.428091  \n",
      "35317           78.005563  \n",
      "48837           78.966853  \n",
      "51325           79.713538  \n",
      "51383           79.447837  \n",
      "51442           79.004341  \n",
      "51518           79.897107  \n",
      "51544           79.078142  \n",
      "\n",
      "High overlap comparisons saved to: /home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/results/Inspection/high_overlap_comparisons.csv\n",
      "Low overlap comparisons saved to: /home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/results/Inspection/low_overlap_comparisons.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the file paths\n",
    "input_csv_path = '/home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/results/Hypersphere_Overlap_Per_Person.csv'  # Update with your sorted input CSV path\n",
    "output_inspection_path = '/home/nmichelotti/Desktop/Embeddings/embeddings_for_n8/results/Inspection'  # Update with your desired output directory for inspection\n",
    "\n",
    "os.makedirs(output_inspection_path, exist_ok=True)\n",
    "\n",
    "# Read the sorted CSV file\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Identify comparisons with high and low overlap percentages\n",
    "high_overlap_threshold = 99\n",
    "low_overlap_threshold = 80\n",
    "\n",
    "high_overlap_df = df[df['overlap_percentage'] >= high_overlap_threshold]\n",
    "low_overlap_df = df[df['overlap_percentage'] < low_overlap_threshold]\n",
    "\n",
    "# Save high and low overlap comparisons for further inspection\n",
    "high_overlap_file = os.path.join(output_inspection_path, 'high_overlap_comparisons.csv')\n",
    "low_overlap_file = os.path.join(output_inspection_path, 'low_overlap_comparisons.csv')\n",
    "\n",
    "high_overlap_df.to_csv(high_overlap_file, index=False)\n",
    "low_overlap_df.to_csv(low_overlap_file, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
